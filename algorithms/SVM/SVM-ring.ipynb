{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_separable = pd.read_csv('../../input/A2-ring/A2-ring-separable.txt', sep=\"\\t\", header=None)\n",
    "train_merged = pd.read_csv('../../input/A2-ring/A2-ring-merged.txt', sep=\"\\t\", header=None)\n",
    "test = pd.read_csv('../../input/A2-ring/A2-ring-test.txt', sep=\"\\t\", header=None)\n",
    "columns = ['Feature1', 'Feature2', 'Class']\n",
    "train_separable.columns, train_merged.columns, test.columns = columns, columns, columns\n",
    "\n",
    "X_train_sep = train_separable.iloc[:, :-1]\n",
    "y_train_sep = train_separable.iloc[:, -1]\n",
    "X_train_mrg = train_merged.iloc[:, :-1]\n",
    "y_train_mrg = train_merged.iloc[:, -1]\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for Separable Dataset:\n",
      "Kernel: linear, C: 0.1, Mean CV Accuracy: 0.5203\n",
      "Kernel: linear, C: 1, Mean CV Accuracy: 0.5203\n",
      "Kernel: linear, C: 10, Mean CV Accuracy: 0.5203\n",
      "Kernel: rbf, C: 0.1, Mean CV Accuracy: 0.962\n",
      "Kernel: rbf, C: 1, Mean CV Accuracy: 0.9715\n",
      "Kernel: rbf, C: 10, Mean CV Accuracy: 0.9929999999999999\n",
      "Best Model Parameters: {'kernel': 'rbf', 'C': 10}, Best Accuracy: 0.9929999999999999\n",
      "\n",
      "Cross-validation for Merged Dataset:\n",
      "Kernel: linear, C: 0.1, Mean CV Accuracy: 0.5515000000000001\n",
      "Kernel: linear, C: 1, Mean CV Accuracy: 0.5515000000000001\n",
      "Kernel: linear, C: 10, Mean CV Accuracy: 0.5515000000000001\n",
      "Kernel: rbf, C: 0.1, Mean CV Accuracy: 0.7695\n",
      "Kernel: rbf, C: 1, Mean CV Accuracy: 0.7713\n",
      "Kernel: rbf, C: 10, Mean CV Accuracy: 0.7807000000000001\n",
      "Best Model Parameters: {'kernel': 'rbf', 'C': 10}, Best Accuracy: 0.7807000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# parameters kernel and C options for cross-validation\n",
    "kernel_options = ['linear', 'rbf']\n",
    "C_options = [0.1, 1, 10]\n",
    "\n",
    "# function for cross-validation\n",
    "def perform_cross_validation(X, y, kernel_options, C_options):\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    kf = KFold(n_splits=4)\n",
    "\n",
    "    for kernel in kernel_options:\n",
    "        for C in C_options:\n",
    "            cv_accuracy = []\n",
    "\n",
    "            for train, validation in kf.split(X):\n",
    "                clf = SVC(kernel=kernel, C=C, random_state=0, probability=True)\n",
    "                clf.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "                y_pred = clf.predict(X.iloc[validation])\n",
    "                accuracy = accuracy_score(y.iloc[validation], y_pred)\n",
    "                cv_accuracy.append(accuracy)\n",
    "\n",
    "            mean_accuracy = np.mean(cv_accuracy)\n",
    "            print(f\"Kernel: {kernel}, C: {C}, Mean CV Accuracy: {mean_accuracy}\")\n",
    "\n",
    "            if mean_accuracy > best_accuracy:\n",
    "                best_accuracy = mean_accuracy\n",
    "                best_model = clf\n",
    "                best_params = {'kernel': kernel, 'C': C}\n",
    "\n",
    "    print(f\"Best Model Parameters: {best_params}, Best Accuracy: {best_accuracy}\")\n",
    "    return best_model\n",
    "\n",
    "print(\"Cross-validation for Separable Dataset:\")\n",
    "best_model_sep = perform_cross_validation(X_train_sep, y_train_sep, kernel_options, C_options)\n",
    "\n",
    "print(\"\\nCross-validation for Merged Dataset:\")\n",
    "best_model_mrg = perform_cross_validation(X_train_mrg, y_train_mrg, kernel_options, C_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training for Separable Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separable Dataset - Percentage Classification Error on Training Set: 0.42%\n"
     ]
    }
   ],
   "source": [
    "# train the model on the entire separable training set\n",
    "best_model_sep.fit(X_train_sep, y_train_sep.values.ravel())\n",
    "\n",
    "# predict on the separable training set\n",
    "y_pred_train_sep = best_model_sep.predict(X_train_sep)\n",
    "\n",
    "# confusion matrix for the separable training set\n",
    "cm_train_sep = confusion_matrix(y_train_sep, y_pred_train_sep)\n",
    "\n",
    "# elements of the confusion matrix\n",
    "n00_train_sep = cm_train_sep[0][0]  # True Negatives\n",
    "n01_train_sep = cm_train_sep[0][1]  # False Positives\n",
    "n10_train_sep = cm_train_sep[1][0]  # False Negatives\n",
    "n11_train_sep = cm_train_sep[1][1]  # True Positives\n",
    "\n",
    "# classification error calculation for the separable training set\n",
    "classification_error_percentage_train_sep = 100 * (n01_train_sep + n10_train_sep) / (n00_train_sep + n11_train_sep + n01_train_sep + n10_train_sep)\n",
    "print(f\"Separable Dataset - Percentage Classification Error on Training Set: {classification_error_percentage_train_sep}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training for Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset - Percentage Classification Error on Training Set: 21.7%\n"
     ]
    }
   ],
   "source": [
    "# train the model on the entire merged training set\n",
    "best_model_mrg.fit(X_train_mrg, y_train_mrg.values.ravel())\n",
    "\n",
    "# predict on the merged training set\n",
    "y_pred_train_mrg = best_model_mrg.predict(X_train_mrg)\n",
    "\n",
    "# confusion matrix for the merged training set\n",
    "cm_train_mrg = confusion_matrix(y_train_mrg, y_pred_train_mrg)\n",
    "\n",
    "# elements of the confusion matrix\n",
    "n00_train_mrg = cm_train_mrg[0][0]  # True Negatives\n",
    "n01_train_mrg = cm_train_mrg[0][1]  # False Positives\n",
    "n10_train_mrg = cm_train_mrg[1][0]  # False Negatives\n",
    "n11_train_mrg = cm_train_mrg[1][1]  # True Positives\n",
    "\n",
    "# classification error calculation for the merged training set\n",
    "classification_error_percentage_train_mrg = 100 * (n01_train_mrg + n10_train_mrg) / (n00_train_mrg + n11_train_mrg + n01_train_mrg + n10_train_mrg)\n",
    "print(f\"Merged Dataset - Percentage Classification Error on Training Set: {classification_error_percentage_train_mrg}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset for Separable Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set (Separable): 0.9948\n",
      "Confusion Matrix (Separable):\n",
      "[[5290   43]\n",
      " [   9 4658]]\n",
      "Percentage Classification Error on Test Set (Separable): 0.52%\n"
     ]
    }
   ],
   "source": [
    "# retrain the model on the entire separable training set\n",
    "best_model_sep.fit(X_train_sep, y_train_sep.values.ravel())\n",
    "\n",
    "# predict on the test set\n",
    "y_pred_test_sep = best_model_sep.predict(X_test)\n",
    "\n",
    "# calculate test accuracy for separable dataset\n",
    "test_accuracy_sep = accuracy_score(y_test, y_pred_test_sep)\n",
    "print(f\"Accuracy on Test Set (Separable): {test_accuracy_sep}\")\n",
    "\n",
    "# display the confusion matrix for separable dataset\n",
    "cm_sep = confusion_matrix(y_test, y_pred_test_sep)\n",
    "print(f\"Confusion Matrix (Separable):\\n{cm_sep}\")\n",
    "\n",
    "# classification error calculation for the test set\n",
    "n00_sep = cm_sep[0][0]\n",
    "n01_sep = cm_sep[0][1]\n",
    "n10_sep = cm_sep[1][0]\n",
    "n11_sep = cm_sep[1][1]\n",
    "classification_error_percentage_sep = 100 * (n01_sep + n10_sep) / (n00_sep + n11_sep + n01_sep + n10_sep)\n",
    "print(f\"Percentage Classification Error on Test Set (Separable): {classification_error_percentage_sep}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset for Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set (Merged): 0.9788\n",
      "Confusion Matrix (Merged):\n",
      "[[5308   25]\n",
      " [ 187 4480]]\n",
      "Percentage Classification Error on Test Set (Merged): 2.12%\n",
      "AUC Score for Separable Dataset: 1.00%\n",
      "AUC Score for Merged Dataset: 1.00%\n"
     ]
    }
   ],
   "source": [
    "# retrain the model on the entire merged training set\n",
    "best_model_mrg.fit(X_train_mrg, y_train_mrg.values.ravel())\n",
    "\n",
    "# predict on the test set\n",
    "y_pred_test_mrg = best_model_mrg.predict(X_test)\n",
    "\n",
    "# calculate test accuracy for merged dataset\n",
    "test_accuracy_mrg = accuracy_score(y_test, y_pred_test_mrg)\n",
    "print(f\"Accuracy on Test Set (Merged): {test_accuracy_mrg}\")\n",
    "\n",
    "# display the confusion matrix for merged dataset\n",
    "cm_mrg = confusion_matrix(y_test, y_pred_test_mrg)\n",
    "print(f\"Confusion Matrix (Merged):\\n{cm_mrg}\")\n",
    "\n",
    "# classification error calculation for the test set\n",
    "n00_mrg = cm_mrg[0][0]\n",
    "n01_mrg = cm_mrg[0][1]\n",
    "n10_mrg = cm_mrg[1][0]\n",
    "n11_mrg = cm_mrg[1][1]\n",
    "classification_error_percentage_mrg = 100 * (n01_mrg + n10_mrg) / (n00_mrg + n11_mrg + n01_mrg + n10_mrg)\n",
    "print(f\"Percentage Classification Error on Test Set (Merged): {classification_error_percentage_mrg}%\")\n",
    "\n",
    "\n",
    "\n",
    "# ensure the model is trained\n",
    "best_model_sep.fit(X_train_sep, y_train_sep.values.ravel())\n",
    "\n",
    "# predict probabilities on the test set for the separable dataset\n",
    "y_prob_sep = best_model_sep.predict_proba(X_test)[:, 1]\n",
    "fpr_sep, tpr_sep, _ = roc_curve(y_test, y_prob_sep)\n",
    "roc_auc_sep = auc(fpr_sep, tpr_sep)\n",
    "print(f\"AUC Score for Separable Dataset: {roc_auc_sep:.2f}%\") \n",
    "\n",
    "\n",
    "# ensure the model is trained\n",
    "best_model_mrg.fit(X_train_mrg, y_train_mrg.values.ravel())\n",
    "\n",
    "# predict probabilities on the test set for the merged dataset\n",
    "y_prob_mrg = best_model_mrg.predict_proba(X_test)[:, 1]\n",
    "fpr_mrg, tpr_mrg, _ = roc_curve(y_test, y_prob_mrg)\n",
    "roc_auc_mrg = auc(fpr_mrg, tpr_mrg)\n",
    "print(f\"AUC Score for Merged Dataset: {roc_auc_mrg:.2f}%\") \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
